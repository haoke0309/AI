{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "使用Yolo探测法，要训练好一个优秀的Yolo模型需要很多数据和计算力的，所以，本次编程使用了开源的已经训练好了的Yolo模型。Yolo给出结果后，进行剔除小概率边框和非最大值抑制，这部分由我们自己实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Lambda, Conv2D\n",
    "from keras.models import load_model, Model\n",
    "from yolo_utils import read_classes, read_anchors, generate_colors, preprocess_image, draw_boxes, scale_boxes\n",
    "from yad2k.models.keras_yolo import yolo_head, yolo_boxes_to_corners, preprocess_true_boxes, yolo_loss, yolo_body\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如何制作数据集\n",
    "* 如果要制造一台自动驾驶汽车，那么必须首先实现车辆探测系统，这样才能避免与其它车辆相撞。\n",
    "* 为了采集数据，可以在汽车上面安装一个照相机，然后开着车在马路上溜达，照相机会每秒拍一张照片，其实百度地图里面的全景模式也是通过这种方式采集照片的\n",
    "* 采集到照片后，需要给这些相片打上标签，如下图所示：\n",
    "    <img src=\"nb_images/box_label.png\" style=\"width:500px;height:250;\">\n",
    "<caption><center> <u> **图 1** </u>: 给图片打标签<br> </center></caption>\n",
    "\n",
    "图中的p<sub>c</sub>表示有物体的概率,1就表示100%有物体，0表示绝对没有物体。c表示物体的种类，是行人还是汽车...其实有两种表示方法，假如你要识别80种物体，那么一种方法是用1到80的整数来表示不同的种类，上图中c=3就表示是汽车；另一种方法是用一个有80个元素的向量的表示，也就是说每个元素代表一个种类，如果值是1就表示肯定是这个种类，如果是0就表示绝对不可能是这个种类，在前面的文章中我们主要使用的是这种方法。而在本次实战编程中，我们会两种方法都用，具体取决于在某个步骤时用哪个方法比较方便。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo探测法\n",
    "YOLO 是一个非常流行的算法，因为它不仅精度高，而且由于计算量较小还可以被用于实时探测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO模型细节\n",
    "使用github已经训练好的YOLO模型：\n",
    "    * 这个模型的输入维度是（m, 608, 608, 3）。\n",
    "    m是图片的个数，608是图片的像素值\n",
    "    * 它会输入识别出来的物体类别以及它的边框坐标，每个边框都对应着6个元素\n",
    "    （pc, bx, by, bn, bw, c）。当然，如果c是用一个包含80个元素的向量来表示的话，那么每个边框就对应着85个元素\n",
    "    * 因为这个YOLO模型使用来5个anchor boxes，并且图片被分成来19个格子，所以这个模型最终输出的维度是（m, 19, 19, 5, 85）\n",
    "\n",
    "大致维度情况就是（m，608， 608，3）-> YOLO模型（CNN网络）-> (m, 19, 19,5, 85),如下图所示：\n",
    "    <img src=\"nb_images/architecture.png\" style=\"width:700px;height:400;\">\n",
    "<caption><center> <u> **图 2** </u>: <br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为这个模型使用了5个anchor boxes（大小不同的框框），所以每个小格子都对应了5组包含85个元素的向量，所以维度是(19, 19, 5, 85)。而为了简单起见，会把后面两个维度扁平化在一起，所以维度就变成了(19, 19, 425)。\n",
    "\n",
    "<img src=\"nb_images/flatten.png\" style=\"width:700px;height:400;\">\n",
    "<caption><center> <u> **图 3** </u>: **扁平化后面两个维度**<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将p<sub>c</sub>与后面的c相乘，就会得到每个种类的“最终”概率值。p<sub>c</sub>  x  c=有物体的概率 x 某个种类的概率。\n",
    "\n",
    "<img src=\"nb_images/probability_extraction.png\" style=\"width:700px;height:400;\">\n",
    "<caption><center> <u> **图 4** </u>: **图中计算结果表明box1有物体并且是汽车的概率为0.44.**<br> </center></caption>\n",
    "\n",
    "我们可以用假设为格子填充不同颜色的方式来辅助我们理解YOLO算法的一些内部过程。不同颜色代表着不同种类的物体。\n",
    "某些格子被填充为了橙色，就代表YOLO算法在这格子中统计得到的数据后发现，关联的5个anchor boxes中p<sub>c</sub>与后面的c相乘得到的结果是汽车的概率最高。\n",
    "\n",
    "<img src=\"nb_images/proba_map.png\" style=\"width:300px;height:300;\">\n",
    "<caption><center> <u> **图 5** </u><br> </center></caption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外一种辅助理解的方式是画出YOLO探测出的边框。如下图所示。每个格子都对应着5个anchor boxes，所以每个格子都有5个边框被探测出来,边框的颜色也代表着不同种类。当然，下图中只画出了一些有物体概率比较高的格子对应的边框。其实总边框应该有1805个，19x19x5 = 1805。\n",
    "\n",
    "<img src=\"nb_images/anchor_map.png\" style=\"width:200px;height:200;\">\n",
    "<caption><center> <u> **图 6** </u><br> </center></caption>\n",
    "\n",
    "虽然上图中只画出了部分高概率的边框，但是还是太多了。实践中，我们会先去掉哪些概率小的边框，然后再使用非最大值抑制算法来去掉哪些重叠的边框。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 过滤掉概率小的边框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold =.6):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "    box_confidence -- 装载着每个边框的pc，维度是（19，19，5，1）\n",
    "    boxes -- 装载着每个边框的bx，by，bh，bw，维度是（19，19，5，4）\n",
    "    box_class_probs -- 装载着每个边框的80个种类的概率，维度是（19，19，5，80）\n",
    "    threshold -- 阈值，概率低于这个值的边框会被过滤掉\n",
    "    \n",
    "    返回值：\n",
    "    scores -- 装载保留下的那些边框的概率，维度是（None，）\n",
    "    boxes -- 装载保留下的那些边框的坐标（bx，by，bh，bw），维度是（None, 4）\n",
    "    classes -- 装载保留下的那些边框的种类的索引，维度是（None，）\n",
    "    \n",
    "    返回值维度中的None，因为不知道有多少个边框被过滤掉了，有多少被保留下了\n",
    "    \"\"\"\n",
    "    \n",
    "    #将px和c相乘\n",
    "    box_scores = np.multiply(box_confidence, box_class_probs)\n",
    "    \n",
    "    #之前将keras as K\n",
    "    box_classes = K.argmax(box_scores,axis=-1)#获取改了吧最大的那个种类的索引\n",
    "    box_class_scores =K.max(box_scores, axis=-1)#获取概率最大的那个种类的概率值\n",
    "    \n",
    "    #采集一个过滤器。当某个种类的概率值大雨等于阈值时\n",
    "    #对应这个种类的filtering_mask中的位置就是True，否则为False\n",
    "    #所以filtering_mask 就是[False, True, .., False, True]这种形式\n",
    "    filtering_mask =K.greater_equal(box_class_scores, threshold)\n",
    "    \n",
    "    #用完上面的过滤器来过滤掉那些小概率的边框\n",
    "    #过滤完成后，scores和boxes， classes里面就只装载来概率大的边框的概率值和坐标以及种类索引\n",
    "    scores = tf.boolean_mask(box_class_scores, filtering_mask)\n",
    "    boxes = tf.boolean_mask(boxes,filtering_mask)\n",
    "    classes =tf.boolean_mask(box_classes, filtering_mask)\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "scores[2] = 10.750582\n",
      "boxes[2] = [ 8.426533   3.2713668 -0.5313436 -4.9413733]\n",
      "classes[2] = 7\n",
      "scores.shape = (?,)\n",
      "boxes.shape = (?, 4)\n",
      "classes.shape = (?,)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as test_a:\n",
    "    box_confidence = tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1)\n",
    "    boxes = tf.random_normal([19, 19, 5, 4], mean=1, stddev=4, seed = 1)\n",
    "    box_class_probs = tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1)\n",
    "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = 0.5)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.shape))\n",
    "    print(\"classes.shape = \" + str(classes.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非最大值抑制 Non-max suppression\n",
    "上面使用阈值过滤掉了一些小概率边框，但是依然有很多重叠的边框，这一步我们将只用非最大抑制Non-max suppression（NMS）技术来过滤掉那些重叠的边框\n",
    "\n",
    "<img src=\"nb_images/non-max-suppression.png\" style=\"width:500px;height:400;\">\n",
    "<caption><center> <u> **图 7** </u>: 左图中3个边框预测的其实都是同一辆车，通过NMS后，去掉重叠的边框，只保留概率值最大的那个，得到右图 <br> </center></caption>\n",
    "\n",
    "NMS的主要步骤如下：\n",
    "    1.找到概率值最高的一个边框\n",
    "    2.找到与这个边框高度重叠的其它边框，也就是交并比很高的其它边框，然后过滤掉它们，当然，交并比到底多高才过滤掉，为此会给定一个阈值iou_threshold.\n",
    "    3.重复进行上面两步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_non_max_suppression(scores, boxes, classes, max_boxes=10, iou_threshold =.5):\n",
    "    \"\"\"\n",
    "    参考：\n",
    "    scores -- 前面yolo_filter_boxes 函数保留下的那些边框概率值，维度是（None,）\n",
    "    boxes -- 前面yolo_filter_boxes 函数保留下的那些边框的坐标（bx, by, bh, bw), 维度是（None,4）\n",
    "    classes --前面yolo_filter_boxes 函数保留下的那些边框的种类的索引，维度是（None，）\n",
    "    max_boxes -- 最多想要保留多少个边框\n",
    "    iou_threshold -- 交并比，这是一个阈值，也就是说交并比大雨这个阈值的边框才会被进行非最大值抑制处理\n",
    "    \n",
    "    returns:\n",
    "    scores -- NMS保留下的那些边框的概率值，维度是（，None）\n",
    "    boxes -- NMS保留下的那些边框的坐标，维度是（4，None）\n",
    "    classes -- NMS保留下的那些边框的种类的索引，维度是（，None）\n",
    "    \"\"\"\n",
    "    max_boxes_tensor = K.variable(max_boxes, dtype='int32')\n",
    "    K.get_session().run(tf.variables_initializer([max_boxes_tensor]))\n",
    "    \n",
    "    #tensorflow为我们提供来一个NMS函数，我们直接调用就可以来tf.image.non_max_suppression().\n",
    "    #这个函数会返回NMS后保留下来的边框的索引\n",
    "    nums_indices = tf.image.non_max_suppression(boxes, scores, max_boxes_tensor, iou_threshold=iou_threshold)\n",
    "    \n",
    "    #通过上面的索引来分别获取被保留的边框的相关概率值，坐标以及种类的索引\n",
    "    scores = K.gather(scores, nums_indices)\n",
    "    boxes = K.gather(boxes, nums_indices)\n",
    "    classes = K.gather(classes, nums_indices)\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mac/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mac/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mac/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mac/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "scores[2] = 6.938395\n",
      "boxes[2] = [-5.299932    3.1379814   4.450367    0.95942086]\n",
      "classes[2] = -2.2452729\n",
      "scores.shape = (10,)\n",
      "boxes.shape = (10, 4)\n",
      "classes.shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as test_b:\n",
    "    scores = tf.random_normal([54,], mean=1, stddev=4, seed = 1)\n",
    "    boxes = tf.random_normal([54, 4], mean=1, stddev=4, seed = 1)\n",
    "    classes = tf.random_normal([54,], mean=1, stddev=4, seed = 1)\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
    "    print(\"classes.shape = \" + str(classes.eval().shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整合前两个函数，过滤掉最后多余的边框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_eval(yolo_outputs, image_shape = (720., 1280.), max_boxes=10, score_threshold =.6, iou_threshold=.5):\n",
    "    \"\"\"\n",
    "    参数：\n",
    "    yolo_outputs -- yolo模型的输出结果\n",
    "    image_shape -- 图像的原始像素，因为网上的yolo需要的图像像素是608，\n",
    "                -- 而我们的原始图像是720 * 1280的，所以在输入到yolo\n",
    "                -- 前会转成608的；同理，我们也会将yolo的输出结果转回到\n",
    "                -- 720 * 1280\n",
    "    max_boxes -- 希望最多识别出多少个边框\n",
    "    score_threshold -- 概率值阈值\n",
    "    iou_threshold -- 交并比阈值\n",
    "    \n",
    "    return:\n",
    "    scores -- 最终保留下的那些边框的概率值，维度是（， None）\n",
    "    boxes -- 最终保留下的那些边框的坐标，维度是（4， None）\n",
    "    classes -- 最终保留下的那些边框的种类的索引，维度是（，None）\n",
    "    \"\"\"\n",
    "    ### 将yolo输出结果分成3份，分别表示概率值，坐标，种类索引\n",
    "    box_confidence, box_xy, box_wh, box_class_probs = yolo_outputs\n",
    "    \n",
    "    #因为yolo模型使用的坐标表示法是（x, y, w, h）,所以先将其转成（x1, y1, x2, y2）的形式\n",
    "    boxes = yolo_boxes_to_corners(box_xy, box_wh)\n",
    "    \n",
    "    #使用我们前面实现的yolo_filter_boxes函数过滤掉概率值低于阈值的边框\n",
    "    scores, boxes, classes = yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold = score_threshold)\n",
    "    \n",
    "    # 将（608，608）转回（702，1280）\n",
    "    boxes = scale_boxes(boxes, image_shape)\n",
    "    \n",
    "    #使用我们前面实现的yolo_non_max_suppression过滤掉重叠的边框\n",
    "    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold = iou_threshold)\n",
    "    \n",
    "    return scores, boxes, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores[2] = 138.79124\n",
      "boxes[2] = [1292.3297  -278.52167 3876.9893  -835.56494]\n",
      "classes[2] = 54\n",
      "scores.shape = (10,)\n",
      "boxes.shape = (10, 4)\n",
      "classes.shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as test_b:\n",
    "    yolo_outputs = (tf.random_normal([19, 19, 5, 1], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 2], mean=1, stddev=4, seed = 1),\n",
    "                    tf.random_normal([19, 19, 5, 80], mean=1, stddev=4, seed = 1))\n",
    "    scores, boxes, classes = yolo_eval(yolo_outputs)\n",
    "    print(\"scores[2] = \" + str(scores[2].eval()))\n",
    "    print(\"boxes[2] = \" + str(boxes[2].eval()))\n",
    "    print(\"classes[2] = \" + str(classes[2].eval()))\n",
    "    print(\"scores.shape = \" + str(scores.eval().shape))\n",
    "    print(\"boxes.shape = \" + str(boxes.eval().shape))\n",
    "    print(\"classes.shape = \" + str(classes.eval().shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用yolo模型进行车辆探测\n",
    "结合github上训练好的yolo模型以及我们自己实现的过滤函数来进行车辆探测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建一个graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mac/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = K.get_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义种类以及anchor box和像素"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "已经将种类和anchor box的信息保存在了‘coco_classes.txt’和‘yolo_anchors.txt’文件中了\n",
    "把它们读出来\n",
    "我们的原始图像像素是（720.， 1280）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = read_classes('model_data/coco_classes.txt')\n",
    "anchors = read_anchors('model_data/yolo_anchors.txt')\n",
    "image_shape =(720. , 1280.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载已经训练好了的yolo模型\n",
    "如果执行这句话时出现错误提示‘The kernel appears to have died. it will restart automatically’,那么你就要重新生成与自己开发环境匹配的yolo.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "yolo_model = load_model(\"model_data/yolo.h5\")\n",
    "#上面已经报错，SystemError：unknown opcode，是因为直接跑了别人跑出来的模型\n",
    "#需要重新生成与自己开发环境匹配的yolo.h5,步骤如下:\n",
    "#1.将本文档目录下的YAD2Kmaster文件夹复制到c盘下\n",
    "#2.打开Anaconda prompt\n",
    "#3.执行activate tensorflow\n",
    "#4.执行cd C:\\YAD2Kmaster命令\n",
    "#5.执行python yad2k.py yolov2.cfg yolov2.weights model_data/yolo.h5\n",
    "#6.用c盘的YAD2Kmaster文件夹下的model_data替换掉本文档目录下的model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 608, 608, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 608, 608, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 608, 608, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 608, 608, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 304, 304, 32) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 304, 304, 64) 18432       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 304, 304, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 304, 304, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 152, 152, 64) 0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 152, 152, 128 73728       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 152, 152, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 152, 152, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 152, 152, 64) 8192        leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 152, 152, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 152, 152, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 152, 152, 128 73728       leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 152, 152, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 152, 152, 128 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 76, 76, 128)  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 76, 76, 256)  294912      max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 76, 76, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 76, 76, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 76, 76, 128)  32768       leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 76, 76, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 76, 76, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 76, 76, 256)  294912      leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 76, 76, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 76, 76, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 38, 38, 256)  0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 38, 38, 512)  1179648     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 38, 38, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 38, 38, 512)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 38, 38, 256)  131072      leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 38, 38, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 38, 38, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 38, 38, 512)  1179648     leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 38, 38, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 38, 38, 512)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 38, 38, 256)  131072      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 38, 38, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 38, 38, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 38, 38, 512)  1179648     leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 38, 38, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 38, 38, 512)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 19, 19, 512)  0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 19, 19, 1024) 4718592     max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 19, 19, 1024) 4096        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 19, 19, 512)  524288      leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 19, 19, 512)  2048        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 19, 19, 512)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 19, 19, 1024) 4718592     leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 19, 19, 1024) 4096        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 19, 19, 512)  524288      leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 19, 19, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 19, 19, 512)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 19, 19, 1024) 4718592     leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 19, 19, 1024) 4096        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 19, 19, 1024) 9437184     leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 19, 19, 1024) 4096        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 38, 38, 64)   32768       leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 38, 38, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 19, 19, 1024) 9437184     leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 38, 38, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 19, 19, 1024) 4096        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "space_to_depth_x2 (Lambda)      (None, 19, 19, 256)  0           leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 19, 19, 1280) 0           space_to_depth_x2[0][0]          \n",
      "                                                                 leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 19, 19, 1024) 11796480    concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 19, 19, 1024) 4096        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 19, 19, 1024) 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 19, 19, 425)  435625      leaky_re_lu_22[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 50,983,561\n",
      "Trainable params: 50,962,889\n",
      "Non-trainable params: 20,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "yolo_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将yolo模型的输出结果转换成我们需要的格式\n",
    "因为yolo_model输出的维度是(m, 19, 19, 5, 85),所以我们要转换一下，这样好满足我们的yolo_eval函数的输入格式要求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_outputs = yolo_head(yolo_model.output, anchors, len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 过滤边框"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yolo_model输出的yolo_outputs里面包含了它探测到的所有的边框。下面使用我们自己实现的过滤函数yolo_eval\n",
    "来过滤掉多余的边框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "socres, boxes, classes = yolo_eval(yolo_outputs, image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始探测图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用前面构建好的graph来探测图片中的车辆\n",
    "def predict(sess, image_file):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    sess -- 前面我们创建的包含了YOLO模型和过滤函数的graph\n",
    "    image_file -- 待探测的图像\n",
    "    \"\"\"\n",
    "\n",
    "    # 将图片读取出来，并且转换成608像素\n",
    "    image, image_data = preprocess_image(\"images/\" + image_file, model_image_size = (608, 608))\n",
    "\n",
    "    # 运行我们之前构建好的graph\n",
    "    out_scores, out_boxes, out_classes = sess.run([scores, boxes, classes], feed_dict={yolo_model.input: image_data, K.learning_phase(): 0})\n",
    "\n",
    "\n",
    "    # 打印出找到了几个边框\n",
    "    print('Found {} boxes for {}'.format(len(out_boxes), image_file))\n",
    "    # 为种类分配颜色\n",
    "    colors = generate_colors(class_names)\n",
    "    # 将找到的边框在图片上画出来\n",
    "    draw_boxes(image, out_scores, out_boxes, out_classes, class_names, colors)\n",
    "    image.save(os.path.join(\"out\", image_file), quality=90)\n",
    "    # 将画出边框的图片显示出来\n",
    "    output_image = scipy.misc.imread(os.path.join(\"out\", image_file))\n",
    "    imshow(output_image)\n",
    "    \n",
    "    return out_scores, out_boxes, out_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value Variable_1\n\t [[node Variable_1/read (defined at /Users/mac/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:402) ]]\n\nOriginal stack trace for 'Variable_1/read':\n  File \"/Users/mac/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/mac/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/mac/anaconda3/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"/Users/mac/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"/Users/mac/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-31-66631d8a2d1f>\", line 6, in <module>\n    scores, boxes, classes = yolo_eval(yolo_outputs)\n  File \"<ipython-input-30-f4ac5c0a773d>\", line 31, in yolo_eval\n    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold = iou_threshold)\n  File \"<ipython-input-26-e27aa97c7c6c>\", line 15, in yolo_non_max_suppression\n    max_boxes_tensor = K.variable(max_boxes, dtype='int32')\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 402, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 259, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 220, in _variable_v1_call\n    shape=shape)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 198, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2511, in default_variable_creator\n    shape=shape)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 263, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1568, in __init__\n    shape=shape)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1755, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 86, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4253, in identity\n    \"Identity\", input=input, name=name)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1356\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1357\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1341\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1429\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_1\n\t [[{{node Variable_1/read}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-2cc816bc6de7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-79eb3c97b534>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(sess, image_file)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# 运行我们之前构建好的graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mout_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0myolo_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1173\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1350\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1368\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value Variable_1\n\t [[node Variable_1/read (defined at /Users/mac/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:402) ]]\n\nOriginal stack trace for 'Variable_1/read':\n  File \"/Users/mac/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/mac/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/mac/anaconda3/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n    self._run_once()\n  File \"/Users/mac/anaconda3/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n    handle._run()\n  File \"/Users/mac/anaconda3/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n    user_expressions, allow_stdin,\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n    return runner(coro)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-31-66631d8a2d1f>\", line 6, in <module>\n    scores, boxes, classes = yolo_eval(yolo_outputs)\n  File \"<ipython-input-30-f4ac5c0a773d>\", line 31, in yolo_eval\n    scores, boxes, classes = yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold = iou_threshold)\n  File \"<ipython-input-26-e27aa97c7c6c>\", line 15, in yolo_non_max_suppression\n    max_boxes_tensor = K.variable(max_boxes, dtype='int32')\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 402, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 259, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 220, in _variable_v1_call\n    shape=shape)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 198, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\", line 2511, in default_variable_creator\n    shape=shape)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 263, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1568, in __init__\n    shape=shape)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\", line 1755, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py\", line 86, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4253, in identity\n    \"Identity\", input=input, name=name)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3616, in create_op\n    op_def=op_def)\n  File \"/Users/mac/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 2005, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "out_scores, out_boxes, out_classes = predict(sess, \"test.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
